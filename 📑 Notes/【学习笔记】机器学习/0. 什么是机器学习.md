## 概述

机器学习是人工智能学科的一个分支，简单来讲，就是让机器能够通过数据自发的学习和改进性能，而无需显式编程。实现层面来讲，机器学习需要通过算法，从历史数据中总结规律，并将这个规律用于未来的预测和做出决策。

## 三大范式

机器学习有三大范式：[[监督学习]]、[[无监督学习]]和[[强化学习]]。

| **类型**    | 特点                                | 典型应用             |
| --------- | --------------------------------- | ---------------- |
| **监督学习**  | 使用**带标签的数据**（输入-输出对）训练模型，用于预测或分类。 | 房价预测、图像分类、垃圾邮件检测 |
| **无监督学习** | 数据无标签，模型自行发现隐藏结构（如聚类、降维）。         | 客户分群、异常检测、数据压缩   |
| **强化学习**  | 模型通过与环境交互的**奖励/惩罚**机制学习最优策略。      | 自动驾驶、游戏AI、机器人控制  |

## 机器学习的关键概念

| 概念                            | 含义                                             |
| ----------------------------- | ---------------------------------------------- |
| 特征（feature）                   | 输入的数据变量。                                       |
| 标签（label）                     | 监督学习中的目标输出。                                    |
| 模型（model）                     | 从数据中学习到的数学公式函数（如线性回归、决策树）                      |
| 训练（train）                     | 用数据去拟合模型参数。                                    |
| 预测（predict）                   | 训练好的数据去预测新数据。                                  |
| 损失函数 (loss function)          | 衡量模型预测结果与真实值之间差异的数学函数，是模型优化的直接目标。              |
| 优化算法 (optimization algorithm) | 优化算法用于调整模型参数（如权重、偏置），以最小化损失函数。其本质是求解损失函数的极小值点。 |

## 机器学习的三要素

机器学习的三要素是：数据、模型和算法。
数据：机器学习是数据驱动的。数据驱动是指基于**客观的量化数据**，通过**主动的数据采集分析**以支持决策。
模型：模型指的是基于数据 x 做出决策 y 的假设函数。模型可以有不同的形态：[[计算型]]和[[规则型]]等。
算法：算法是实现模型的具体计算方法。具体而言，[[统计学习]]基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解出最优模型的过程，就是算法。简单来讲，算法是指如何通过数学或编程手段求解模型中的参数或结构。

> [!NOTE] 模型和算法
> 如果将模型比喻成一个“公式”，那么算法就是求解公式的计算步骤。例如，对于一个线性回归模型，那么梯度下降就是求解这个模型参数的一个算法。

## 机器学习的经典算法

监督学习：
- [[线性回归]]
- [[决策树]]
- [[支持向量机]]

无监督学习：
- [[K-Means 聚类]]
- [[PCA 降维]]

强化学习
- [[Q-Learning]]（策略优化）

## 机器学习的核心任务

机器学习有如下四类核心任务：

| 任务类别 | 内容                                          | 应用场景                      |
| ---- | ------------------------------------------- | ------------------------- |
| 分类   | 使用分类的数据进行模型训练，然后对新样本进行精确分类和预测。              | 构建用户画像、情感分析、用户行为检测、图像识别分类 |
| 聚类   | 从海量数据中识别数据的相似性和差异性，按照共同点聚合为多个类别。            | 市场细化、模式识别、空间数据分析          |
| 异常检测 | 对数据点的分布规律进行分析，识别与正常数据差异较大的离群点。              | 日常运行监控、风险识别、舞弊检测          |
| 回归   | 根据对已知属性值数据的训练，为模型寻找最佳的拟合参数，然后基于模型预测新样本的输出值。 | 趋势预测、价格预测、流量预测            |

## 机器学习的基本流程

机器学习的常见的工作流包含四个步骤：数据预处理、模型训练、模型评估、新样本预测。

**数据预处理**：将原始的数据转化为模型可用的格式。
- **输入**：未处理的数据+标签
- **处理过程**：特征处理+幅度缩放、特征选择、维度约减、采样
- **输出**：测试集+训练集

**模型学习**：从数据中学习规律。
- **模型选择**：[[线性回归]]、[[随机森林]]、[[神经网络]]等。
- **模型训练**：用训练集拟合模型，[[超参调优]]（如 [[GridSearchCV]]）。

**模型评估**：了解模型对于数据集测试的得分，验证模型性能。
- 使用测试集评估指标（准确率、RMSE、F1分数等）
- [[交叉验证]]：多次重新划分训练集和测试集进行训练，避免单次训练的随机性。
- 分析过拟合、欠拟合（[[学习曲线]]、[[混淆矩阵]]）
- 决定是否需要重新调整模型。

**新样本预测**：对数据集合以外的新样本进行预测。
- 对新数据做相同的预处理（例如复用训练集的归一化参数）
- 调用训练好的模型进行预测。
- 输出预测结果。

## 机器学习解决什么问题

### 分类问题

分类问题是指根据已知样本的某些特征，判断一个新的样本属于哪个已知的样本类。
分类问题包括：[[二分类问题]]、[[多类分类问题]]、[[多标签分类问题]]。
常见分类算法：[[KNN算法]]、[[逻辑回归算法]]、[[朴素贝叶斯算法]]、[[决策树算法]]、[[随机森林算法]]、[[GBDT模型]]、[[XGBoost模型]]、[[支持向量机模型]]。

### 回归问题

回归问题是指根据已知样本的特征，构建一个模型，用于预测新样本所对应的连续数值输出。
回归问题包括：[[一元线性回归]]、[[多元线性回归]]、[[非线性回归]]、[[岭回归]]、[[Lasso回归]] 等。
常见回归算法：[[线性回归模型]]、[[支持向量回归（SVR）模型]]、[[决策树回归模型]]、[[随机森林回归模型]]、[[GBDT回归模型]]、[[XGBoost回归模型]]、[[神经网络回归模型]] 等。

### 聚类问题

聚类问题是指在没有已知类别标签的情况下，根据样本之间的特征相似性，将样本自动划分为若干个内部相似、外部差异较大的簇（Cluster）。聚类问题是典型的[[无监督学习]]任务。
聚类常见应用：数据探索、模式发现、异常检测、降维预处理等场景。
常见聚类算法：[[K-means聚类算法]]、[[层次聚类算法]]、[[DBSCAN算法]]、[[高斯混合模型（GMM）]]、[[谱聚类算法]] 等。

### 降维问题

降维问题是指当我们手头的数据有很多特征（或称维度）时，我们希望在不丢失重要信息的前提下，用更少的特征来表达这些数据。
降维常见应用：数据可视化、特征压缩、噪声过滤、加快模型训练速度等。
常见降维算法：[[主成分分析（PCA）]]、[[t-SNE算法]]、[[UMAP算法]]、[[自编码器（AutoEncoder）]] 等。

### 异常检测

异常检测问题是指，识别与正常模式显著不同的样本，这些样本可能代表错误、欺诈或异常事件。
异常检测常见应用：欺诈识别、入侵检测、故障预警等。
常见异常检测方法：[[基于统计的方法]]、[[孤立森林（Isolation Forest）]]、[[局部离群因子（LOF）]]、[[自编码器]]、[[One-Class SVM]] 等。

### 模型评估相关概念

### 训练集

训练集是一组样本数据，用于训练机器学习模型以识别数据中的规律或完成特定任务（如预测、分类、聚类等）。在有监督学习中，训练集包含带有标签的数据，每条数据由输入特征和对应标签组成，模型通过学习这些数据来拟合输入特征与输出标签之间的映射关系（例如分类或回归）。在无监督学习中，训练集由不带标签的输入数据组成，模型通过分析数据的内在结构，自动发现规律，例如进行聚类、降维或异常检测等操作。

### 测试集

测试集是一组独立的样本数据，不参与模型训练，用于评估模型的性能和泛化能力。在有监督学习中，测试集包含输入特征和对应标签，模型基于测试集的预测结果与真实标签对比，计算如准确率、均方误差等指标以评估效果。在无监督学习中，测试集可用于评估模型发现的规律（如聚类质量）或生成结果的质量。测试集与训练集应具有相似的分布但不能有数据重叠，以确保评估的客观性。

### 经验误差

经验误差（或训练误差）是模型在训练集上的预测误差，通常通过损失函数（如均方误差或交叉熵）计算，反映模型对训练数据的拟合程度。经验误差并不是越小越好，因为过低的经验误差可能仅表示模型过度拟合训练数据，而不代表其在未见过的新数据上的表现（即泛化能力）。模型优劣的衡量主要基于其泛化误差，通常通过测试集或验证集上的表现来估计。如果模型在训练集上表现很好（低经验误差），但在测试集上表现较差（高测试误差），**则表明模型出现了过拟合**，可能由于模型过于复杂或训练数据不足。解决过拟合可通过[[正则化]]、增加数据或调整模型复杂度等方法。

###  平均模型

**平均模型**是指在**无数个从同一数据分布中抽取的训练集**上训练得到的模型的**预测期望**。换句话说，它是模型在理论上对同一输入 样本的预测的平均值。


> [!NOTE] 平均模型的直观解释
> 想象你有一个数据集的生成分布（例如，房价数据，包含面积、位置等特征和对应的房价）。每次从这个分布中随机抽取一个训练集（比如1000条数据），然后用它训练一个模型（比如线性回归）。
> 由于每次抽取的训练集数据不同（样本随机性），训练出的模型参数（例如权重）会略有不同，因此对同一个输入的预测值也会有所不同。
> 如果你重复这个过程无数次（抽取无数个训练集，训练无数个模型），然后取这些模型对的预测值的平均值，这个平均预测就是平均模型的输出。
> 平均模型是偏差-方差分解中的理论概念，用来分析模型的系统性误差（偏差）和随机性误差（方差）。
> 它帮助我们理解：**即使消除了训练数据的随机性（通过平均），模型的预测是否仍然偏离真实值（即偏差）。**

### 偏差

偏差是指模型拟合的偏差程度，它表示模型预测的期望值与真实数据的生成函数（目标函数）之间的系统性差异，反映模型拟合能力的不足。在评估偏差时，我们应该使用平均模型去评估。
简单的模型往往高偏差（无法准确反映真实模型的底层实际逻辑）；复杂的模型可以做到和真实曲线的偏差较小。

### 方差

方差反映的是模型的对于不同数据集训练的平稳程度，或者说是对训练数据变化的敏感程度。方差衡量了模型由于训练数据的随机性而导致的预测不稳定性。当一个模型存在对于某组训练数据的过拟合时，它往往表现为对不同的训练集预测差异很大，也即方差很大。


> [!NOTE] 偏差和方差的平衡
> 偏差反映的是 “一个模型是否能够准确的拟合真实模型”，而方差反映的是“一个模型对于给定不同的训练集数据的敏感程度”。模型越简单，则它的方差往往越小，但是偏差通常越大，此时模型表现为为欠拟合；反之，模型越复杂，则他的偏差可以做到比较小（即通过复杂的模型尽可能拟合真实数据背后的底层关系），方差可能越大（即一点输入的差异可能导致结果出现很大的偏离）。因此，在模型评估上，需要针对偏差和方差进行平衡，得到最合适的模型。

### 模型的性能度量指标

模型的性能度量指标反应了模型是否能够准确实现目标任务需求。因此针对不同的任务需求，会使用不同的度量指标去衡量模型性能。

| 问题类型 | 度量指标                              |
| ---- | --------------------------------- |
| 回归问题 | 平均绝对误差、均方误差、均方根误差、R²              |
| 分类问题 | 错误率、精确率、查准率、查全率、F1、ROC曲线、AUC曲线、R² |
回归问题指标：
- 平均绝对误差（MAE）：又叫平均绝对离差，是所有标签值和模型回归预测值偏差的绝对值的平均。
- 平均绝对百分误差（MAPE）：对 MAE 的一种改进，考虑了绝对误差相较于真实值的比例。
- 均方误差（MSE）：均方误差是所有标签值和模型回归预测值的偏差的平方的平均。
- 均方根误差（RMSE）：也称标准误差，在均方误差基础上进行开方运算，用于衡量观测值和真值之间的误差。
- R²（决定系数）：反映因变量的全部变异能通过目前的回归模型被模型中的自变量解释的比例。比例越接近于1，表示当前的回归模型对数据的解释越好，越能精确描述数据的真实分布。换句人话：因变量变化有多少比例是由于我们模型中自变量影响（或说可以理论通过我们模型自变量解释）的，而剩下的部分则是和自变量完全无关的残差噪声项。R² 比例为1，表示我们选择的这些自变量可以完全解释因变量的变化。例如：如果你做一个线性回归，预测“身高”对“体重”的影响，得到 R²=0.85，那表示：身高这个变量能够解释 **85% 的体重变异**，其余 15% 可能由饮食、年龄、性别等未建模因素造成。

分类问题指标：
- 错误率：分类错误的样本占样本总数的比例。
- 精确率：分类正确的样本占样本总数的比例。
- 查准率（准确率）：真正正确的个数占你认为正确的样本比例。（通俗点讲，你找到的结果是否都是对的）
- 查全率（召回率）：检索结果中真正正确的个数占所有正确个数的比例。（通俗点讲，所有正确结果是否都被你找到了）
- [[F1指标]]：综合考虑查准率与查全率的度量，一般是基于查准率与查全率的调和平均定义。
- [[ROC曲线]]（受试者工作特性曲线）：ROC曲线展示的是毛线哦ing在不同的分类阈值下，真阳性率（TPR）和假阳性率（FPR）之间的关系。
- [[AUC]]：ROC曲线下的面积，代表了样本预测的排序质量。

### 评估方法

在没有“未知数据”的情况下，如何使用样本数据对模型进行评估？
常见方法有：[[留出法]]（Hold-out）、[[交叉验证法]]（Cross Validation）、[[自助法]]（Bootstrap）。
- 留出法：最常见的评估方法之一，简单来说就是从训练样本中保留出验证样本集，这部分数据不用于训练，仅用于评估。
- 交叉验证法：将样本数据进行分组，每轮使用一组数据作为验证集，其他数据用于训练，最终将不同分组的训练结果取平均来减少方差。
- 自助法：自助法是通过重复、有放回的从原始样本中抽取子样本的方法，来估计统计量（如模型准确率、均值、方差等）在总体中的分布。

###  模型的调优和选择准则

我们希望找到对当前问题表达能力好，且模型复杂度较低的模型。
常见的选择方法包括：
- 验证集评估选择：将样本数据切分为训练集和验证集，在训练集上训练模型，在验证集上进行评估。
- 网格搜索/随机搜索交叉验证：通过网格搜索/随机搜索产出候选的超参数组，对每一组超参数使用交叉验证进行评估，最后选出最好的超参数组。
- [[贝叶斯优化]]：通过贝叶斯优化进行超参数调优。


📌 参考：[图解机器学习 | 机器学习基础知识](https://www.showmeai.tech/article-detail/185)  